@article{Arif2019,
abstract = {2D ultrasound (US) image guidance is used in minimally invasive procedures in the liver to visualize the target and the needle. Needle insertion using 2D ultrasound keeping the transducer position to view needle and reach target is challenging. Dedicated needle holders attached to the US transducer help to target in plane and at a specific angle. A drawback of this is that, the probe is fixed to the needle and cannot be rotated to assess the position of the needle in a perpendicular plane. In this study, we propose an automatic needle detection and tracking method using 3D US imaging to improve image guidance and visualization of the target in the liver with respect to the needle during these interventional procedures. The method utilizes a convolutional neural network for detection of the needle in 3D US images. In a subsequent step, the output of the convolutional neural network is used to detect needle candidates, which are fed into a final tracking step to determine the real needle position. The needle position is used to present two perpendicular cross-sectional planes of the 3D US image containing the needle in both directions. Performance of the method was evaluated in phantoms and in-vivo data by calculating the needle position distance and needle orientation angle between segmented needles and reference ground truth needles, which were manually annotated by an observer. The method successfully detects the needle position and orientation with mean errors of 1 mm and 2° respectively. The proposed method yields a robust automatic needle detection and visualization at a frame rate of 3 Hz in 3D ultrasound imaging of the liver.},
author = {Arif, Muhammad and Moelker, Adriaan and van Walsum, Theo},
doi = {10.1016/j.media.2019.02.002},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/Automatic needle detection and real-time Bi-planar needle visualization during 3D ultrasound scanning of the liver.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Automatic needle segmentation,Convolutional neural network,Needle tracking,Percutaneous interventions,Real-time,Ultrasound image guidance},
pages = {104--110},
publisher = {Elsevier B.V.},
title = {{Automatic needle detection and real-time Bi-planar needle visualization during 3D ultrasound scanning of the liver}},
url = {https://doi.org/10.1016/j.media.2019.02.002},
volume = {53},
year = {2019}
}
@article{Ayvali2015,
abstract = {Image-guided interventions have become the standard of care for needle-based procedures. The success of the image-guided procedures depends on the ability to precisely locate and track the needle. This work is primarily focused on 2D ultrasound-based tracking of a hollow needle (cannula) that is composed of straight segments connected by shape memory alloy actuators. An in-plane tracking algorithm based on optical flow was proposed to track the cannula configuration in real-time. Optical flow is a robust tracking algorithm that can easily run on a CPU. However, the algorithm does not perform well when it is applied to the ultrasound images directly due to the intensity variation in the images. The method presented in this work enables using the optical flow algorithm on ultrasound images to track features of the needle. By taking advantage of the bevel tip, Circular Hough transform was used to accurately locate the needle tip when the imaging is out-of-plane. Through experiments inside tissue phantom and ex-vivo experiments in bovine kidney, the success of the proposed tracking methods were demonstrated. Using the methods presented in this work, quantitative information about the needle configuration is obtained in real- time which is crucial for generating control inputs for the needle and automating the needle insertion.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Ayvali, Elif and Desai, Jaydev P.},
doi = {10.1007/s10439-014-1208-0},
eprint = {15334406},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleTracking/Optical Flow-Based Tracking of Needles and Needle-Tip Localization Using Circular Hough Transform in Ultrasound Images.pdf:pdf},
isbn = {0000000000000},
issn = {0090-6964},
journal = {Annals of Biomedical Engineering},
mendeley-groups = {n{\_}Tracking,n{\_}detection},
month = {aug},
number = {8},
pages = {1828--1840},
pmid = {24655651},
title = {{Optical Flow-Based Tracking of Needles and Needle-Tip Localization Using Circular Hough Transform in Ultrasound Images}},
url = {http://link.springer.com/10.1007/s10439-014-1208-0},
volume = {43},
year = {2015}
}
@inproceedings{Orlando2019,
author = {Orlando, Nathan and Snir, Jonatan and Barker, Kevin and Hoover, Douglas and Fenster, Aaron},
booktitle = {Medical Imaging 2019: Image-Guided Procedures, Robotic Interventions, and Modeling},
doi = {10.1117/12.2513082},
editor = {Fei, Baowei and Linte, Cristian A.},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/Power Doppler ultrasound imaging with mechanical perturbation for improved intraoperative needle tip identification during prostate brachytherapy{\_} a phantom study.pdf:pdf},
isbn = {9781510625495},
mendeley-groups = {n{\_}detection},
month = {mar},
number = {March},
pages = {111},
publisher = {SPIE},
title = {{Power Doppler ultrasound imaging with mechanical perturbation for improved intraoperative needle tip identification during prostate brachytherapy: a phantom study}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10951/2513082/Power-Doppler-ultrasound-imaging-with-mechanical-perturbation-for-improved-intraoperative/10.1117/12.2513082.full},
volume = {1095131},
year = {2019}
}
@misc{Henken2017,
abstract = {{\textcopyright} 2016, The Author(s). This study aims to develop and evaluate a manually controlled steerable needle that is compatible with and visible on MRI to facilitate full intra-procedural control and accurate navigation in percutaneous interventions. The steerable needle has a working channel that provides a lumen to a cutting stylet or a therapeutic instrument. A steering mechanism based on cable-operated compliant elements is integrated in the working channel. The needle can be steered by adjusting the orientation of the needle tip through manipulation of the handle. The steering mechanism is evaluated by recording needle deflection at constant steering angles. A steering angle of 20.3° results in a deflection of 9.1–13.3 mm in gelatin and 4.6–18.9 mm in porcine liver tissue at an insertion depth of 60 mm. Additionally, the possibility to control the needle path under MRI guidance is evaluated in a gelatin phantom. The needle can be steered to targets at different locations while starting from the same initial position and orientation under MRI guidance with generally available sequences. The steerable needle offers flexibility to the physician in control and choice of the needle path when navigating the needle toward the target position, which allows for optimization of individual treatment and may increase target accuracy.},
author = {Henken, Kirsten R. and Seevinck, Peter R. and Dankelman, Jenny and van den Dobbelsteen, John J.},
booktitle = {Medical and Biological Engineering and Computing},
doi = {10.1007/s11517-016-1490-0},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/[MRI]Manually controlled steerable needle for MRI‑guided percutaneous interventions.pdf.pdf:pdf},
issn = {17410444},
keywords = {In vitro,MRI compatible,MRI-guided interventions,Needle deflection,Needle steering},
mendeley-groups = {Percutaneous{\_}inventions},
number = {2},
pages = {235--244},
title = {{Manually controlled steerable needle for MRI-guided percutaneous interventions}},
volume = {55},
year = {2017}
}
@article{Jun2018,
abstract = {Insertion-responsive microneedles (IRMNs) have been developed that can enable instantaneous drug delivery without applying patches through immediate tip separation upon insertion.},
author = {Jun, Hyesun and Ahn, Myun-hwan and Choi, In-jeong and Baek, Seung-ki and Park, Jung-hwan and Choi, Seong-O},
doi = {10.1039/C8RA02334D},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/(2018{\_}Drug{\_}Delivery)Immediate separation of microneedle tips from base array during skin insertion for instantaneous drug delivery.pdf:pdf},
issn = {2046-2069},
journal = {RSC Advances},
mendeley-groups = {Percutaneous{\_}inventions},
number = {32},
pages = {17786--17796},
publisher = {Royal Society of Chemistry},
title = {{Immediate separation of microneedle tips from base array during skin insertion for instantaneous drug delivery}},
url = {http://xlink.rsc.org/?DOI=C8RA02334D},
volume = {8},
year = {2018}
}
@inproceedings{Kaya2014,
author = {Kaya, Mert and Bebek, Ozkan},
booktitle = {2014 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2014.6907574},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/Needle Localization Using Gabor Filtering in 2D Ultrasound Images.pdf:pdf},
isbn = {9781479936854},
mendeley-groups = {n{\_}detection},
number = {1050-4729},
pages = {4881--4886},
publisher = {IEEE},
title = {{Needle Localization Using Gabor Filtering in 2D Ultrasound Images}},
year = {2014}
}
@article{Kaya2019,
abstract = {Percutaneous needle procedures are among the most frequently performed minimally invasive surgical procedure. For tracking the needle tip in the tissue, 2D ultrasound (US) imaging is commonly used; however, the low resolution of the images creates a challenge for tracking. This paper describes a robotic system that can perform US image guided biopsies by tracking the needle and the target simultaneously. It uses a template-based visual tracking method for small and deformable targets. During the experiments, a needle was inserted into realistic phantoms using a 5-DOF robot. The 2D US probe was held by a robotic arm that was servoed along the needle path. The 3D shape of the needle was estimated using the 2D transverse US images, which was used to align the needle axis with the 2D imaging plane. The accuracy of the visual needle tip tracking was evaluated using an optical tracking system, and a computed tomography scanner was used to determine the accuracy of the 3D needle shape estimation method. Target reaching accuracies were measured using an electromagnetic tracking system. The results of the experiments showed that the proposed system can track the needle tip in 2D US guided needle procedures in real-time with a sub-millimeter positional error.},
author = {Kaya, Mert and Senel, Enes and Ahmad, Awais and Bebek, Ozkan},
doi = {10.1016/j.mechatronics.2018.12.002},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleTracking/Visual needle tip tracking in 2D US guided robotic interventions.pdf:pdf},
issn = {09574158},
journal = {Mechatronics},
keywords = {2D ultrasound,3D needle shape visualization,Needle tip,Robotic biopsy,Visual tracking},
month = {feb},
number = {December 2018},
pages = {129--139},
title = {{Visual needle tip tracking in 2D US guided robotic interventions}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0957415818301910},
volume = {57},
year = {2019}
}
@article{Kaya2015,
abstract = {{\textcopyright} 2015 IEEE.In this paper, real-time needle tip tracking method using 2D ultrasound (US) images for robotic biopsies is presented. In this method, the needle tip is estimated with the Gabor filter based image processing algorithm, and the estimation noise is reduced with the Kalman filter. This paper also presents the needle tip tracking simulation to test accuracy of the Kalman filter under position misalignments and tissue deformations. In order to execute proposed method in real-time, the bin packing method is used and the processing time is reduced by 56{\%}, without a GPU. The proposed method was tested in four different phantoms and water medium. The accuracy of the needle tip estimation was measured with optical tracking system, and root mean square error (RMS) of the tip position is found to be 1.17 mm. The experiments showed that the algorithm could track the needle tip in real-time.},
author = {Kaya, Mert and Senel, Enes and Ahmad, Awais and Orhan, Orcun and Bebek, Ozkan},
doi = {10.1109/ICAR.2015.7251432},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/Real-time Needle Tip Localization in 2D Ultrasound Images for Robotic Biopsies(Kalman).pdf:pdf},
isbn = {9781467375092},
journal = {IEEE International Conference on Robotics and Automation},
mendeley-groups = {n{\_}estimation,n{\_}detection},
pages = {47--52},
publisher = {IEEE},
title = {{Real-time needle tip localization in 2D ultrasound images for robotic biopsies}},
year = {2015}
}
@article{Li2018,
abstract = {{\textcopyright} 2018, Biomedical Engineering Society. As a low-cost needle navigation system, AngleNav may be used to improve the accuracy, speed, and ease of CT-guided needle punctures. The AngleNav hardware includes a wireless device with a microelectromechanical (MEMS) tracker that can be attached to any standard needle. The physician defines the target, desired needle path and skin entry point on a CT slice image. The accuracy of AngleNav was first tested in a 3D-printed calibration platform in a benchtop setting. An abdominal phantom study was then performed in a CT scanner to validate the accuracy of the device's angular measurement. Finally, an in vivo swine study was performed to guide the needle towards liver targets (n = 8). CT scans of the targets were used to quantify the angular errors and needle tip-to-targeting distance errors between the planned needle path and the final needle position. The MEMS tracker showed a mean angular error of 0.01° with a standard deviation (SD) of 0.62° in the benchtop setting. The abdominal phantom test showed a mean angular error of 0.87° with an SD of 1.19° and a mean tip-to-target distance error of 4.89 mm with an SD of 1.57 mm. The animal experiment resulted in a mean angular error of 6.6° with an SD of 1.9° and a mean tip-to-target distance error of 8.7 mm with an SD of 3.1 mm. These results demonstrated the feasibility of AngleNav for CT-guided interventional workflow. The angular and distance errors were reduced by 64.4 and 54.8{\%} respectively if using AngleNav instead of freehand insertion, with a limited number of operators. AngleNav assisted the physicians to deliver accurate needle insertion during CT-guided intervention. The device could potentially reduce the learning curve for physicians to perform CT-guided needle targeting.},
author = {Li, Rui and Xu, Sheng and Pritchard, William F. and Karanian, John W. and Krishnasamy, Venkatesh P. and Wood, Bradford J. and Tse, Zion Tsz Ho},
doi = {10.1007/s10439-017-1968-4},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/CT{\_}AngleNav{\_} MEMS Tracker to Facilitate CT-Guided Puncture.pdf:pdf},
issn = {15739686},
journal = {Annals of Biomedical Engineering},
keywords = {Angular tracking,CT-guided biopsy or ablation,MEMS sensor,Tracker},
mendeley-groups = {n{\_}detection},
number = {3},
pages = {452--463},
title = {{AngleNav: MEMS Tracker to Facilitate CT-Guided Puncture}},
volume = {46},
year = {2018}
}
@article{Mignon2018,
abstract = {Robotic control of needle bending aims at increasing the precision of percutaneous procedures. Ultrasound feedback is preferable for its clinical ease of use, cost and compactness but raises needle detection issues. In this paper, we propose a complete system dedicated to robotized guidance of a flexible needle under 3D ultrasound imaging. This system includes a medical robot dedicated to transperineal needle positioning and insertion, a rapid path planning for needle steering using bevel-tip needle natural curvature in tissue, and an ultrasound-based automatic needle detection algorithm. Since ultrasound-based automatic needle steering is often made difficult by the needle localization in biological tissue, we quantify the benefit of using flexible echogenic needles for robotized guidance under 3D ultrasound. The "echogenic" term refers to the etching of microstructures on the needle shaft. We prove that these structures improve needle visibility and detection robustness in ultrasound images. We finally present promising results when reaching targets using needle steering. The experiments were conducted with various needles in different media (synthetic phantoms and ex vivo biological tissue). For instance, with nitinol needles the mean accuracy is 1.2 mm (respectively 3.8 mm) in phantoms (resp. biological tissue).},
author = {Mignon, Paul and Poignet, Philippe and Troccaz, Jocelyne},
doi = {10.1007/s10439-018-2061-3},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/Automatic Robotic Steering of Flexible Needles from 3D Ultrasound Images in Phantoms and Ex Vivo Biological Tissue.pdf:pdf},
issn = {15739686},
journal = {Annals of Biomedical Engineering},
keywords = {3D ultrasound,Echogenic needle,Ex-vivo tissue,Needle detection,Needle steering,Robotics},
mendeley-groups = {n{\_}detection},
number = {9},
pages = {1385--1396},
title = {{Automatic Robotic Steering of Flexible Needles from 3D Ultrasound Images in Phantoms and Ex Vivo Biological Tissue}},
volume = {46},
year = {2018}
}
@inproceedings{Mignon2016,
abstract = {This paper introduces a new robust 3D ultrasound needle detection approach integrated in a 3D needle steering system associated to a real-time path planning. The robustness of an existing algorithm is improved by limiting the needle detection to a curvilinear region of interest (ROI) using a novel mechanical-based prediction model. This linear model is also used in a Kalman filter to reduce detection noise and reject false detections. These two improvements drastically increase quality of our feedback. Finally, the 3D needle steering system is able to reach a target in phantoms with a maximal error of 0.8 mm without obstacle and 1.6 mm with obstacle.},
author = {Mignon, Paul and Poignet, Philippe and Troccaz, Jocelyne},
booktitle = {2016 14th International Conference on Control, Automation, Robotics and Vision (ICARCV)},
doi = {10.1109/ICARCV.2016.7838840},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/3DUltraSound/Beveled-Tip Needle-Steering Using 3D Ultrasound, Mechanical-Based Kalman Filter and Curvilinear ROI Prediction.pdf:pdf},
isbn = {978-1-5090-3549-6},
keywords = {Kalman filter,Needle steering,needle detection,ultrasound},
mendeley-groups = {3DUltrasound,n{\_}detection},
month = {nov},
pages = {1--6},
publisher = {IEEE},
title = {{Beveled-tip needle-steering using 3D ultrasound, mechanical-based Kalman filter and curvilinear ROI prediction}},
url = {http://ieeexplore.ieee.org/document/7838840/},
year = {2016}
}
@article{Mwikirize2018a,
author = {Mwikirize, Cosmas and Nosher, John L. and Hacihaliloglu, Ilker},
doi = {10.1007/s11548-018-1721-y},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/Convolution neural networks for real-time needle detection and localization in 2D ultrasound.pdf:pdf},
issn = {18616429},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {Convolution neural networks,Minimally invasive procedures,Needle localization,Ultrasound},
mendeley-groups = {n{\_}detection},
number = {5},
pages = {647--657},
publisher = {Springer International Publishing},
title = {{Convolution neural networks for real-time needle detection and localization in 2D ultrasound}},
url = {https://doi.org/10.1007/s11548-018-1721-y},
volume = {13},
year = {2018}
}
@article{Mwikirize2018,
abstract = {We propose a novel framework for enhancement and localization of steeply
inserted hand-held needles under in-plane 2D ultrasound guidance.
Depth-dependent attenuation and non-axial specular reflection hinder
visibility of steeply inserted needles. Here, we model signal
transmission maps representative of the attenuation probability within
the image domain. The maps are employed in a contextual regularization
framework to recover needle shaft and tip information. The needle tip is
automatically localized by line-fitting along the local-phase-directed
trajectory, followed by statistical optimization.
The proposed method was tested on 300 ex vivo ultrasound scans collected
during insertion of an epidural needle into freshly excised porcine and
bovine tissue. A tip localization accuracy of was achieved.
The proposed method could be useful in challenging procedures where
needle shaft and tip are inconspicuous. Improved needle localization
results compared to previously proposed methods suggest that the
proposed method is promising for further clinical evaluation.},
author = {Mwikirize, Cosmas and Nosher, John L. and Hacihaliloglu, Ilker},
doi = {10.1007/s11548-017-1698-y},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/超声图像自动检测穿刺针的挑战/2018{\_}Signal attenuation maps for needle enhancement and localization in 2D ultrasound.pdf:pdf},
issn = {18616429},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {Anesthesia,Attenuation map,Needle enhancement,Tip localization,Ultrasound},
mendeley-groups = {n{\_}detection},
number = {3},
pages = {363--374},
publisher = {Springer International Publishing},
title = {{Signal attenuation maps for needle enhancement and localization in 2D ultrasound}},
url = {https://doi.org/10.1007/s11548-017-1698-y},
volume = {13},
year = {2018}
}
@article{Nachabe2015,
abstract = {Objective This study presents the first in vivo real-time optical tissue characterization during image-guided percutaneous intervention using near-infrared diffuse optical spectroscopy sensing at the tip of a needle. The goal of this study was to indicate transition boundaries from healthy tissue to tumors, namely, hepatic carcinoma, based on the real-time feedback derived from the optical measurements. Materials and Methods Five woodchucks with hepatic carcinoma were used for this study. The woodchucks were imaged with contrast-enhanced cone beam computed tomography with a flat panel detector C-arm system to visualize the carcinoma in the liver. In each animal, 3 insertions were performed, starting from the skin surface toward the hepatic carcinoma under image guidance. In 2 woodchucks, each end point of the insertion was confirmed with pathologic examination of a biopsy sample. While advancing the needle in the animals under image guidance such as fluoroscopy overlaid with cone beam computed tomography slice and ultrasound, optical spectra were acquired at the distal end of the needles. Optical tissue characterization was determined by translating the acquired optical spectra into clinical parameters such as blood, water, lipid, and bile fractions; tissue oxygenation levels; and scattering amplitude related to tissue density. The Kruskal-Wallis test was used to study the difference in the derived clinical parameters from the measurements performed within the healthy tissue and the hepatic carcinoma. Kurtoses were calculated to assess the dispersion of these parameters within the healthy and carcinoma tissues. Results Blood and lipid volume fractions as well as tissue oxygenation and reduced scattering amplitude showed to be significantly different between the healthy part of the liver and the hepatic carcinoma (P {\{}{\textless}{\}} 0.05) being higher in normal liver tissue. A decrease in blood and lipid volume fractions and tissue oxygenation as well as an increase in scattering amplitude were observed when the tip of the needle crossed the margin from the healthy liver tissue to the carcinoma. The kurtosis for each derived clinical parameter was high in the hepatic tumor as compared with that in the healthy liver indicating intracarcinoma variability. Conclusions Tissue blood content, oxygenation level, lipid content, and tissue density all showed significant differences when the needle tip was guided from the healthy tissue to the carcinoma and can therefore be used to identify tissue boundaries during percutaneous image-guided interventions.},
author = {Nachabé, Rami and Hendriks, Benno H W and Schierling, Ross and Hales, Jasmine and Racadio, Judy M. and Rottenberg, Sven and Ruers, Theo J M and Babic, Drazenko and Racadio, John M.},
doi = {10.1097/RLI.0000000000000149},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/[Percutaneous]Real-Time In Vivo Characterization of Primary Liver Tumors With Diffuse Optical Spectroscopy During Percutaneous Needle Interventions.pdf:pdf},
issn = {15360210},
journal = {Investigative Radiology},
keywords = {cone beam computed tomography,hepatic carcinoma,interventional radiology,near-infrared spectroscopy},
mendeley-groups = {Percutaneous{\_}inventions},
number = {7},
pages = {443--448},
title = {{Real-time in vivo characterization of primary liver tumors with diffuse optical spectroscopy during percutaneous needle interventions: Feasibility study in woodchucks}},
volume = {50},
year = {2015}
}
@article{Park2018,
author = {Park, Hanwook and Kim, Hyejeong and Lee, Sang Joon},
doi = {10.1007/s10439-018-2100-0},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/Optimal Design of Needle Array for Effective Drug Delivery.pdf:pdf},
issn = {0090-6964},
journal = {Annals of Biomedical Engineering},
keywords = {Diffusion,Drug injection,Multi-needle injection,X-ray imaging},
month = {dec},
number = {12},
pages = {2012--2022},
publisher = {Springer US},
title = {{Optimal Design of Needle Array for Effective Drug Delivery}},
url = {https://doi.org/10.1007/s10439-018-2100-0 http://link.springer.com/10.1007/s10439-018-2100-0},
volume = {46},
year = {2018}
}
@article{Priester2013,
abstract = {Robots ultrasound (RUS) can be defined as the combination of ultrasound imaging with a robotic system in medical interventions. With their potential for high precision, dexterity, and repeatability, robots are often uniquely suited for ultrasound integration. Although the field is relatively young, it has already generated a multitude of robotic systems for application in dozens of medical procedures. This paper reviews the robotic ultrasound systems that have been developed over the past two decades and describes their potential impact on modern medicine. The RUS projects reviewed include extracorporeal devices, needle guidance systems, and intraoperative systems.},
author = {Priester, Alan M. and Natarajan, Shyam and Culjat, Martin},
doi = {10.1109/TUFFC.2013.2593},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/RUS/Robotic Ultrasound Systems in Medicine.pdf:pdf},
isbn = {1525-8955},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
mendeley-groups = {RUS},
number = {3},
pages = {507--523},
pmid = {23475917},
title = {{Robotic ultrasound systems in medicine}},
volume = {60},
year = {2013}
}
@article{Raj2019,
author = {Raj, Sean D. and Agrons, Michelle M. and Woodtichartpreecha, Piyanoot and Kalambo, Megan J. and Dogan, Basak E. and Le-Petross, Huong and Whitman, Gary J.},
doi = {10.1111/tbj.13246},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/[MRI]MRI‐guided needle localization{\_} Indications, tips, tricks, and review of the literature.pdf:pdf},
issn = {15244741},
journal = {Breast Journal},
keywords = {MRI-guided needle localization,breast cancer},
mendeley-groups = {Percutaneous{\_}inventions},
number = {July 2018},
pages = {479--483},
title = {{MRI-guided needle localization: Indications, tips, tricks, and review of the literature}},
year = {2019}
}
@article{Renfrew2018,
abstract = {This paper describes a framework of algorithms for the active localization and tracking of flexible needles and targets during image-guided percutaneous interventions. The needle and target configurations are tracked by Bayesian filters employing models of the needle and target motions and measurements of the current system state obtained from an intra-operative imaging system which is controlled by an entropy-minimizing active localization algorithm. Ver-sions of the system were built using particle and unscented Kalman filters and their performance was measured using both simulations and hardware experiments with real mag-netic resonance imaging data of needle insertions into gel phantoms. Performance of the localization algorithms is given in terms of accuracy of the predictions and compu-tational efficiency is discussed.},
author = {Renfrew, Mark and Griswold, Mark and {\c{C}}avuşoĝlu, M. Cenk},
doi = {10.1007/s10514-017-9640-2},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/RUS/Active Localization and Tracking of Needle and Target in Robotic Image-Guided Intervention Systems.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
keywords = {Active sensing,Bayesian filtering,Image-guided interventions,Intra-operative image-guidance,Medical robotics,Needle tracking},
month = {jan},
number = {1},
pages = {83--97},
title = {{Active localization and tracking of needle and target in robotic image-guided intervention systems}},
url = {http://link.springer.com/10.1007/s10514-017-9640-2},
volume = {42},
year = {2018}
}
@article{Rossa2017b,
abstract = {Percutaneous needle insertion is amongst the most prevalent clinical procedures. The effectiveness of needle-base interventions heavily relies on needle targeting accuracy. However, the needle interacts with the surrounding tissue during insertion and deflects away from its intended trajectory. To overcome this problem, a significant research effort has been made towards developing robotic systems to automatically steer bevel-tipped needles percutaneously, which is a comprehensive and challenging control problem. A flexible needle inserted in soft tissue is an under-actuated system with nonholonomic constraints. Closed-loop feedback control of needle in tissue is challenging due to measurement errors, unmodelled dynamics created by tissue heterogeneity, and motion of targets within the tissue. In this paper, we review recent progress made in each of the complementary components that constitute a closed-loop needle steering system, including modelling needle-tissue interaction, sensing needle deflection, controlling needle trajectory, and hardware implementation.},
author = {Rossa, Carlos and Tavakoli, Mahdi},
doi = {10.1016/j.conengprac.2017.03.004},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/navi/rossa2017{\_}Issues in closed-loop needle steering.pdf:pdf},
issn = {09670661},
journal = {Control Engineering Practice},
keywords = {Feedback control,Robotic assistance,Sensors,Steerable needles,Surgical robotics},
number = {March},
pages = {55--69},
publisher = {Elsevier Ltd},
title = {{Issues in closed-loop needle steering}},
url = {http://dx.doi.org/10.1016/j.conengprac.2017.03.004},
volume = {62},
year = {2017}
}
@article{Rossa2016a,
abstract = {This paper proposes a method to predict the deflection of a flexible needle inserted into soft tissue based on the observation of deflection at a single point along the needle shaft.},
author = {Rossa, Carlos and Sloboda, Ron and Usmani, Nawaid and Tavakoli, Mahdi},
doi = {10.1007/s11548-015-1329-4},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needle deflection/EstimatingNeedleTipDeflectioninBiologicalTissuefromaSingleTransverseUltrasoundImageApplicationtoBrachytherapy.pdf:pdf},
issn = {1861-6410},
journal = {International Journal of Computer Assisted Radiology and Surgery},
keywords = {Brachytherapy,Needle insertion,Needle-tissue Interaction,Ultrasound Guidance},
month = {jul},
number = {7},
pages = {1347--1359},
title = {{Estimating needle tip deflection in biological tissue from a single transverse ultrasound image: application to brachytherapy}},
url = {http://link.springer.com/10.1007/s11548-015-1329-4},
volume = {11},
year = {2016}
}
@article{Shellikeri2017a,
abstract = {Navigational software provides real-time fluoroscopic needle guidance
for percutaneous procedures in the Interventional Radiology (IR) suite.
We describe our experience with navigational software for pediatric
percutaneous bone biopsies in the IR suite and compare technical
success, diagnostic accuracy, radiation dose and procedure time with
that of CT-guided biopsies.
Pediatric bone biopsies performed using navigational software (Syngo
iGuide, Siemens Healthcare) from 2011 to 2016 were prospectively
included and anatomically matched CT-guided bone biopsies from 2008 to
2016 were retrospectively reviewed with institutional review board
approval. C-arm CT protocols used for navigational software-assisted
cases included institution-developed low-dose (0.1/0.17 mu
Gy/projection), regular-dose (0.36 mu Gy/projection), or a combination
of low-dose/regular-dose protocols. Estimated effective radiation dose
and procedure times were compared between software-assisted and
CT-guided biopsies.
Twenty-six patients (15 male; mean age: 10 years) underwent
software-assisted biopsies (15 pelvic, 7 lumbar and 4 lower extremity)
and 33 patients (13 male; mean age: 9 years) underwent CT-guided
biopsies (22 pelvic, 7 lumbar and 4 lower extremity). Both modality
biopsies resulted in a 100{\%} technical success rate. Twenty-five of 26
(96{\%}) software-assisted and 29/33 (88{\%}) CT-guided biopsies were
diagnostic. Overall, the effective radiation dose was significantly
lower in software-assisted than CT-guided cases (3.0 +/- 3.4 vs. 6.6 +/-
7.7 mSv, P=0.02). The effective dose difference was most dramatic in
software-assisted cases using low-dose C-arm CT (1.2 +/- 1.8 vs. 6.6 +/-
7.7 mSv, P=0.001) or combined low-dose/regular-dose C-arm CT (1.9 +/-
2.4 vs. 6.6 +/- 7.7 mSv, P=0.04), whereas effective dose was comparable
in software-assisted cases using regular-dose C-arm CT (6.0 +/- 3.5 vs.
6.6 +/- 7.7 mSv, P=0.7). Mean procedure time was significantly lower for
software-assisted cases (91 +/- 54 vs. 141 +/- 68 min, P=0.005).
In our experience, navigational software technology in the IR suite is a
promising alternative to CT guidance for pediatric bone biopsies
providing comparable technical success and diagnostic accuracy with
lower radiation dose and procedure time, in addition to providing
real-time fluoroscopic needle guidance.},
author = {Shellikeri, Sphoorti and Setser, Randolph M. and Hwang, Tiffany J. and Srinivasan, Abhay and Krishnamurthy, Ganesh and Vatsky, Seth and Girard, Erin and Zhu, Xiaowei and Keller, Marc S. and Cahill, Anne Marie},
doi = {10.1007/s00247-017-3830-0},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/[CT]Realtimeneedleguidance{\_}PediatricRadiology{\_}May2017.pdf:pdf},
issn = {14321998},
journal = {Pediatric Radiology},
keywords = {Bone biopsy,Children,Interventional radiology,Navigational software,Needle guidance},
number = {8},
pages = {963--973},
publisher = {Pediatric Radiology},
title = {{Real-time fluoroscopic needle guidance in the interventional radiology suite using navigational software for percutaneous bone biopsies in children}},
volume = {47},
year = {2017}
}
@misc{VandeBerg2019a,
abstract = {During ultrasound-guided percutaneous interventions, needle localization can be a challenge. To increase needle visibility, enhancements of both the imaging methods and the needle surface properties have been investigated. However, a methodical approach to compare potential solutions is currently unavailable. The work described here involves automated image acquisition, analysis and reporting techniques to collect large amounts of data efficiently, delineate relevant factors and communicate effects. Data processing included filtering, line fitting and image intensity analysis steps. Foreground and background image samples were used to compute a contrast-to-noise ratio or a signal ratio. The approach was evaluated in a comparative study of commercially available and custom-made needles. Varied parameters included needle material, diameter and surface roughness. The shafts with kerfed patterns and the trocar and chiba tips performed best. The approach enabled an intuitive polar depiction of needle visibility in ultrasound images for a large range of insertion angles.},
author = {van de Berg, Nick J. and S{\'{a}}nchez-Margallo, Juan A. and van Dijke, Arjan P. and Lang{\o}, Thomas and van den Dobbelsteen, John J.},
booktitle = {Ultrasound in Medicine and Biology},
doi = {10.1016/j.ultrasmedbio.2018.10.004},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/A Methodical Quantification of Needle Visibility and Echogenicity in Ultrasound Images {\_} Elsevier Enhanced Reader.pdf:pdf},
issn = {1879291X},
keywords = {Contrast-to-noise ratio,Echogenicity,Experimental methods,High-echoic range,Needle interventions,Polyvinyl alcohol,Signal ratio,Ultrasound,Visibility},
number = {4},
pages = {998--1009},
title = {{A Methodical Quantification of Needle Visibility and Echogenicity in Ultrasound Images}},
volume = {45},
year = {2019}
}
@article{Waine2015b,
abstract = {This paper introduces an automatic method to visualize 3D needle shapes for reliable assessment of needle placement during needle insertion procedures. Based on partial observations of the needle within a small sample of 2D transverse ultrasound images, the 3D shape of the entire needle is reconstructed. An intensity thresholding technique is used to identify points representing possible needle locations within each 2D ultrasound image. Then, a Random Sample and Consensus (RANSAC) algorithm is used to filter out false positives and fit the remaining points to a polynomial model. To test this method, a set of 21 transverse ultrasound images of a brachytherapy needle embedded within a transparent tissue phantom are obtained and used to reconstruct the needle shape. Results are validated using camera images which capture the true needle shape. For this experimental data, obtaining at least three images from an insertion depth of 50 mm or greater allows the entire needle shape to be calculated with an average error of 0.5 mm with respect to the measured needle curve obtained from the camera image. Future work and application to robotics is also discussed.},
author = {Waine, Michael and Rossa, Carlos and Sloboda, Ronald and Usmani, Nawaid and Tavakoli, Mahdi},
doi = {10.1109/ICRA.2015.7139855},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/超声图像自动检测穿刺针的挑战/3D Shape Visualization of Curved Needles in Tissue from 2D Ultrasound Images using RANSAC.pdf:pdf},
isbn = {VO  -},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Medical Robots and Systems,Object detection, segmentation, categorization},
number = {June},
pages = {4723--4728},
title = {{3D shape visualization of curved needles in tissue from 2D ultrasound images using RANSAC}},
volume = {2015-June},
year = {2015}
}
@article{Waine2016a,
author = {Waine, Michael and Rossa, Carlos and Sloboda, Ron and Usmani, Nawaid and Tavakoli, Mahdi},
doi = {10.1142/S2424905X16400018},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleTracking/Needle Tracking and Deflection Prediction for Robot-Assisted Needle Insertion Using 2D Ultrasound Images.pdf:pdf},
issn = {2424-905X},
journal = {Journal of Medical Robotics Research},
keywords = {brachytherapy,modelling,needle,prostate,tracking,ultrasound},
number = {01},
pages = {1640001},
title = {{Needle Tracking and Deflection Prediction for Robot-Assisted Needle Insertion Using 2D Ultrasound Images}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S2424905X16400018},
volume = {01},
year = {2016}
}
@article{Waine2015c,
abstract = {In this paper we propose an automated method to reconstruct the 3D needle shape during needle insertion procedures using only 2D transverse ultrasound (US) images. Using a set of transverse US images, image processing and random sample consensus (RANSAC) is used to locate the needle within each image and estimate the needle shape. The method is validated with an in-vitro needle insertion setup and a transparent tissue phantom, where two orthogonal cameras are used to capture the true 3D needle shape for verification. Results showed that the use of at least 3 images obtained at 75{\%} of the maximum insertion depth or greater allows for maximum needle shape estimation errors of less than 2 mm. In addition, the needle shape can be calculated consistently as long as the needle can be identified in 30{\%} of the transverse US images obtained. Application to permanent prostate brachytherapy (PPB) is also presented, where the estimated needle shape is compared to manual segmentation and sagittal US images. Our method is intended to help assess needle placement during manual or robotassisted needle insertion procedures after the needle has been inserted.},
author = {Waine, Michael and Rossa, Carlos and Sloboda, Ron and Usmani, Nawaid and Tavakoli, Mahdi},
doi = {10.1109/JBHI.2015.2477829},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/3D Needle Shape Estimation in TRUS-Guided Prostate Brachytherapy Using 2D Ultrasound Images.pdf:pdf},
issn = {2168-2208},
journal = {IEEE journal of biomedical and health informatics},
number = {c},
pages = {1--11},
pmid = {26372660},
title = {{3D Needle Shape Estimation in TRUS-Guided Prostate Brachytherapy Using 2D Ultrasound Images.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26372660},
volume = {2194},
year = {2015}
}
@article{Xu2018a,
abstract = {In the 2D ultrasound image of ultrasound-guided percutaneous needle
insertions, it is difficult to determine the positions of needle axis
and tip because of the existence of artifacts and other noises. In this
work the speckle is regarded as the noise of an ultrasound image, and a
novel algorithm is presented to detect the needle in a 2D ultrasound
image. Firstly, the wavelet soft thresholding technique based on
BayesShrink rule is used to denoise the speckle of ultrasound image.
Secondly, we add Otsu's thresholding method and morphologic operations
to pre-process the ultrasound image. Finally, the localization of the
needle is identified and positioned in the 2D ultrasound image based on
the maximum likelihood estimation sample consensus (MLESAC) algorithm.
The experimental results show that it is valid for estimating the
position of needle axis and tip in the ultrasound images with the
proposed algorithm. The research work is hopeful to be used in the path
planning and robot-assisted needle insertion procedures.},
author = {Xu, Fei and Gao, Dedong and Wang, Shan and Zhanwen, A.},
doi = {10.1088/1742-6596/1004/1/012037},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/MLESAC Based Localization of Needle Insertion Using 2D Ultrasound Images.pdf:pdf},
issn = {17426596},
journal = {Journal of Physics: Conference Series},
number = {1},
title = {{MLESAC Based Localization of Needle Insertion Using 2D Ultrasound Images}},
volume = {1004},
year = {2018}
}
@article{Chatelain2015,
abstract = {We present a method for the three-dimensional (3D) steering of a flexible needle under 3D ultrasound guidance. The proposed solution is based on a duty-cycling visual servoing strategy we designed in a previous work, and on a new needle tracking algorithm for 3D ultrasound. The flexible needle modeled as a polynomial curve is tracked during automatic insertion using particle filtering. This new tracking algorithm enables real-time closed-loop needle control with 3D ultrasound feedback. Experimental results of a targeting task demonstrate the robustness of the proposed tracking algorithm and the feasibility of 3D ultrasound-guided needle steering.},
author = {Chatelain, Pierre and Krupa, Alexandre and Navab, Nassir},
doi = {10.1109/ICRA.2015.7139497},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/3DUltraSound/3D ultrasound-guided robotic steering of a flexible needle via visual servoing.pdf:pdf},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
mendeley-groups = {3DUltrasound,n{\_}detection},
number = {June},
pages = {2250--2255},
title = {{3D ultrasound-guided robotic steering of a flexible needle via visual servoing}},
volume = {2015-June},
year = {2015}
}
@inproceedings{Younes2018a,
author = {Younes, Hatem and Voros, Sandrine and Troccaz, Jocelyne},
booktitle = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
doi = {10.1109/ISBI.2018.8363787},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleDetection/AUTOMATIC NEEDLE LOCALIZATION IN 3D ULTRASOUND IMAGES FOR BRACHYTHERAPY.pdf:pdf},
isbn = {978-1-5386-3636-7},
month = {apr},
pages = {1203--1207},
publisher = {IEEE},
title = {{Automatic needle localization in 3D ultrasound images for brachytherapy}},
url = {https://ieeexplore.ieee.org/document/8363787/},
year = {2018}
}
@article{Yue2012,
abstract = {Ultrasound navigation technology is used for medical examinations and minimally invasive surgeries. This paper presents an improved method for tracking micro tools as biopsy metallic needles insertion using 3D ultrasound. Previously, the RANSAC [1] algorithm has been implemented to detect the needle inserted in human tissue in a stationary situation. In this paper, the Kalman filter is added to increase the stability of the RANSAC algorithm and realize an application in a dynamic situation. The RANSAC algorithm is used to get the needle axis direction and the position of the needle tip. The speckle tracking method is used to estimate the inserting speed of the needle. The Kalman filter uses the results given by the two methods above as the measurement to make the estimation of the direction of the needle and the position of the needle tip. The simulated results show that in both stationary and dynamic situations, the proposed method gives a more stable and accurate result than the RANSAC algorithm. Keywords:},
archivePrefix = {arXiv},
arxivId = {hal-00810785},
author = {Yue, Z and Liebgott, H and Cachard, C},
eprint = {hal-00810785},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needleTracking/Tracking biopsy needle using Kalman filter and RANSAC algorithm with 3D ultrasound.pdf:pdf},
journal = {Acoustics 2012 Nantes},
keywords = {3d ultrasound,kalman filter,ransac,simulation,tracking},
number = {April},
pages = {231--236},
title = {{Tracking biopsy needle using Kalman filter and RANSAC algorithm with 3D ultrasound}},
url = {http://hal.archives-ouvertes.fr/hal-00810785/},
year = {2012}
}
@article{Mehrjardi2017a,
abstract = {{\textcopyright} 2017 Wiley Periodicals, Inc. We report the case of a 25-year-old female with renal arteriovenous fistula and pseudoaneurysm (PA) formation following renal core-needle biopsy, treated successfully by ultrasound-guided percutaneous embolization with autologous blood clot injection. After inserting a 15-gauge needle within the PA sac, 10 ml of blood was retrieved from the sac, and then reinjected into the PA as well as in the needle tract after the obtained blood completely clotted. The procedure was completed by manual compression of the flank. Follow-up sonographic examinations revealed no complication, and the PA size reduced gradually over time due to fibrotic shrinkage.},
author = {Mehrjardi, Mohammad Zare and Bagheri, Seyed Morteza and Darabi, Mohsen},
doi = {10.1002/jcu.22462},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/Percutaneous{\_}inventions/[US]Successful Ultrasound-Guided Percutaneous Embolization of Renal Pseudoaneurysm by Autologous Blood Clot{\_} Preliminary Report of a New Method.pdf:pdf},
issn = {10970096},
journal = {Journal of Clinical Ultrasound},
keywords = {Autologous blood clot,Percutaneous embolization,Renal pseudoaneurysm,Ultrasound-guided,Vascular intervention},
number = {9},
pages = {592--596},
title = {{Successful ultrasound-guided percutaneous embolization of renal pseudoaneurysm by autologous blood clot: Preliminary report of a new method}},
volume = {45},
year = {2017}
}
@inproceedings{GustaafJ.Vrooijink2013,
author = {Vrooijink, Gustaaf J. and Abayazid, Momen and Misra, Sarthak},
booktitle = {2013 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2013.6630797},
file = {:E$\backslash$:/3-DReconstruction/刘立/reference/ultrasound/ForZiHao/needle estimation/2013{\_}Needle{\_}US{\_}Real-Time Three-Dimensional Flexible Needle Tracking using Two-Dimensional Ultrasound.pdf:pdf},
isbn = {978-1-4673-5643-5},
mendeley-groups = {n{\_}estimation},
month = {may},
pages = {1688--1693},
publisher = {IEEE},
title = {{Real-time three-dimensional flexible needle tracking using two-dimensional ultrasound}},
url = {http://ieeexplore.ieee.org/document/6630797/},
year = {2013}
}
